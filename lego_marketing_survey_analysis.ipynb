{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory.\n",
    "import os\n",
    "wd = r\"C:\\Users\\Jiseong Yang\\git_projects\\Marketing-Management\"\n",
    "wd = wd.replace(\"'\\'\", \"/\")\n",
    "os.chdir(wd)\n",
    "os.getcwd()\n",
    "\n",
    "# Read in the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "kidults_xlsx = \"lego_kidults.xlsx\"\n",
    "kidults_csv = \"lego_kidults.csv\"\n",
    "kidults = pd.read_excel(kidults_xlsx)\n",
    "kidults.to_csv(kidults_csv, encoding = 'utf-8')\n",
    "kidults = pd.read_csv(kidults_csv, encoding = \"utf-8\")\n",
    "\n",
    "# Check the data.\n",
    "kidults.head()\n",
    "kidults.shape\n",
    "kidults\n",
    "\n",
    "# Set the mmaximum number of rows displayed.\n",
    "pd.options.display.max_columns = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of values to map\n",
    "sex = [\"남성\", \"여성\"]\n",
    "region = [\"서울특별시\", \"인천광역시\", \"대전광역시\", \"대구광역시\", \"울산광역시\",\n",
    "          \"부산광역시\", \"광주광역시\", \"세종특별자치시\", \"경기도\", \"강원도\",\n",
    "          \"충청북도\", \"충청남도\", \"전라북도\", \"전라남도\", \"경상북도\", \n",
    "          \"경상남도\", \"제주특별자치도\"]\n",
    "bought = ['구입한 적 있음', '구입한 적은 없으나 앞으로 구입할 의사가 있음',\n",
    "          \"구입한 적이 없으며 앞으로 구입할 의사도 없음\"]\n",
    "my_purpose = [\"선물\", \"수집\", \"완구\", \"교구재\", \"전시용\"]\n",
    "\n",
    "# Erase the weird sex category. \n",
    "kidults = kidults[(kidults[raw_cols[1]] == \"남성\") | (kidults[raw_cols[1]] == \"여성\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last three columns that are unneccessary. \n",
    "kidults = pd.DataFrame(kidults)\n",
    "kidults.columns[-3:]\n",
    "kidults.drop(kidults.columns[-3:], axis = 1, inplace = True)\n",
    "\n",
    "# Remove the first column that are redundant.\n",
    "kidults.drop(kidults.columns[0], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Split the dataset into three parts and merge with the ID column.\n",
    "kidults.columns[48:50]\n",
    "demo = kidults.iloc[:,:8]\n",
    "demo.columns\n",
    "\n",
    "brand = kidults.iloc[:,8:48]\n",
    "brand.columns\n",
    "\n",
    "mix = kidults.iloc[:,48:]\n",
    "mix.columns\n",
    "\n",
    "demo.shape\n",
    "brand.shape\n",
    "mix.shape\n",
    "\n",
    "# Check\n",
    "kidults.shape[1] == demo.shape[1] + brand.shape[1] + mix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the new and old lists of demographic dataset columns. \n",
    "demo_oldcols = demo.columns\n",
    "demo_newcols = [\"sex\", \"age\", \"region\", \"income\", \"bought\", \"my_purpose\", \"present_purpose\", \"present_age\"]\n",
    "len(demo_oldcols) == len(demo_newcols)\n",
    "\n",
    "# Get the new and old lists of brand perception dataset columns.\n",
    "brand_oldcols = brand.columns\n",
    "brand_newcols = []\n",
    "questions = [\"price\", \"purpose\", \"popularity\", \"accuracy\"]\n",
    "for i in range(1, 11):\n",
    "    for j in range(4):\n",
    "        brand_newcols.append(questions[j] + str(i))\n",
    "len(brand_oldcols) == len(brand_newcols)\n",
    "\n",
    "# Get the new and old lists of marketing mix perception dataset columns.\n",
    "mix_oldcols = mix.columns\n",
    "mix_newcols = []\n",
    "marketing_mix = [\"product\", \"price\", \"place\", \"promotion\"]\n",
    "for i in range(4):\n",
    "    for j in range(1,5):\n",
    "        mix_newcols.append(marketing_mix[i] + str(j))\n",
    "mix_newcols.append(\"overall\")\n",
    "len(mix_oldcols) == len(mix_newcols)\n",
    "\n",
    "# Define the function that creates a dictionary of the old and new column names.\n",
    "def get_col_dic(oldcols, newcols):\n",
    "    col_dic = {}\n",
    "    for i in range(len(oldcols)):\n",
    "        col_dic[oldcols[i]] = newcols[i]\n",
    "    return col_dic\n",
    "\n",
    "# Assign the dictionaries created by the fucntion and rename the column names.        \n",
    "demo_columns_dic = get_col_dic(demo_oldcols, demo_newcols)\n",
    "brand_columns_dic = get_col_dic(brand_oldcols, brand_newcols)\n",
    "mix_columns_dic = get_col_dic(mix_oldcols, mix_newcols)\n",
    "\n",
    "demo.rename(columns=demo_columns_dic, inplace=True)\n",
    "brand.rename(columns=brand_columns_dic, inplace=True)\n",
    "mix.rename(columns=mix_columns_dic, inplace=True)\n",
    "\n",
    "# Arrange the column order.\n",
    "demo_col_rearrange = ['sex', 'region', 'bought', 'my_purpose', \n",
    "                      'present_purpose', 'present_age', 'age', 'income']\n",
    "demo = demo[demo_col_rearrange]\n",
    "\n",
    "demo\n",
    "brand\n",
    "mix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the first dataset (demographic dataset)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Drop the gift-related columns. \n",
    "demo.columns\n",
    "demo.drop(demo.columns[4:6], axis =1, inplace = True)\n",
    "\n",
    "# Get the mapping dictionaries.\n",
    "age_mapping = {\n",
    "        \"12세 미만\": 0,\n",
    "        \"12세 이상 19세 미만\": 1, \n",
    "        \"19세 이상 29세 미만\": 2, \n",
    "        \"29세 이상 30세 미만\": 3, \n",
    "        \"30세 이상 40세 미만\": 3, \n",
    "        \"40세 이상 50세 미만\": 4, \n",
    "        \"50세 이상 60세 미만\": 5, \n",
    "        \"60세 이상\": 6\n",
    "        }\n",
    "\n",
    "sex_mapping = {sex: i for i, sex in enumerate(sex)}\n",
    "region_mapping = {region: i for i, region in enumerate(region)}\n",
    "bought_mapping = {bought: i for i, bought in enumerate(bought)}\n",
    "my_purpose_mapping = {my_purpose: i for i, my_purpose in enumerate(my_purpose)}\n",
    "    \n",
    "# Fix the error of the survey question that inquire the age range and encode the ordinal features. (age)    \n",
    "demo.age = demo.age.map(age_mapping)\n",
    "set(demo.age)\n",
    "\n",
    "# Encode the nominal features. (sex, region, bought, my_purpose)\n",
    "nominal_features = [\"sex\", \"region\", \"bought\", \"my_purpose\"]\n",
    "demo[nominal_features[0]] = demo[nominal_features[0]].map(sex_mapping)\n",
    "demo[nominal_features[1]] = demo[nominal_features[1]].map(region_mapping)\n",
    "demo[nominal_features[2]] = demo[nominal_features[2]].map(bought_mapping)\n",
    "demo[nominal_features[3]] = demo[nominal_features[3]].map(my_purpose_mapping)\n",
    "    \n",
    "# Features by types\n",
    "demo_categorical = [\"sex\", \"region\", \"bought\", \"my_purpose\"]\n",
    "demo_numerical = [\"age\", \"income\"]\n",
    "   \n",
    "# Add the knowledge level on brands as features to the demographic dataset. \n",
    "knowledge = brand[brand.filter(regex=\"^accuracy\").columns]\n",
    "demo_numerical = pd.concat([demo[demo_numerical], knowledge], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical features. \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normailze\n",
    "stds = StandardScaler()\n",
    "stds.fit(demo_numerical)\n",
    "demo_stds = pd.DataFrame(stds.transform(demo_numerical))\n",
    "\n",
    "# Rename the columns\n",
    "demo_stds.shape[1]\n",
    "demo_numerical.shape[1]\n",
    "demo_stds.rename(columns=get_col_dic(demo_stds.columns, demo_numerical.columns), inplace = True)\n",
    "\n",
    "# Concatenate the scaled table with categorical tables.\n",
    "demo = pd.concat([demo[demo_categorical], demo_stds], axis =1)\n",
    "demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment the Data by the Level of Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a list of each company's data.\n",
    "brands_data = []\n",
    "for i in range(1,11):\n",
    "    brands_data.append(brand.iloc[:,(i-1)*4:i*4])\n",
    "\n",
    "# Define the function that adds the ID columns.\n",
    "def concat_id(dataset_whole, dataset_brand):\n",
    "    import pandas as pd\n",
    "    dataset_brand = pd.concat([dataset_whole[dataset_whole.columns[0]], dataset_brand], axis = 1)\n",
    "    dataset_brand.rename(columns = {dataset_brand.columns[0]: \"ID\"}, inplace = True)\n",
    "    return dataset_brand\n",
    "\n",
    "# Get the dataset for each brand.\n",
    "lego, sonogong, young_toys, oxford, froebel, montessori, edu_hansol, riot_games, pubg, mojang = brands_data\n",
    "\n",
    "# Get the dataset of each brand.\n",
    "brand_perception_by_knowledge = []\n",
    "\n",
    "# Store them all in a single list.\n",
    "for name in brands_data:\n",
    "    # Combine the dataset with ID columns. \n",
    "    name = concat_id(kidults, name) \n",
    "    \n",
    "    # Filter out the dataset depending on the accuarcy.\n",
    "    brand_ignorant = name[name[name.columns[4]] < 3]\n",
    "    brand_moderate = name[name[name.columns[4]] == 3]\n",
    "    brand_knowledgeable = name[name[name.columns[4]] > 3]\n",
    "    \n",
    "    # Append three different gruops by the level of knowledge to a single list. \n",
    "    brand_perception_by_knowledge.append([brand_ignorant, brand_moderate, brand_knowledgeable])\n",
    "\n",
    "# Wait for a second to prevent the errors.\n",
    "import time\n",
    "time.sleep(1)        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring datasets by brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lego\n",
    "# Ignorant group\n",
    "lego_ignorant = brand_perception_by_knowledge[0][0]\n",
    "lego_ignorant_average = lego_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "lego_moderate = brand_perception_by_knowledge[0][1]\n",
    "lego_moderate_average = lego_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "lego_knowledgeable = brand_perception_by_knowledge[0][2]\n",
    "lego_knowledgeable_average = lego_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Sonogong\n",
    "# Ignorant group\n",
    "sonogong_ignorant = brand_perception_by_knowledge[1][0]\n",
    "sonogong_ignorant_average = sonogong_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "sonogong_moderate = brand_perception_by_knowledge[1][1]\n",
    "sonogong_moderate_average = sonogong_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "sonogong_knowledgeable = brand_perception_by_knowledge[1][2]\n",
    "sonogong_knowledgeable_average = sonogong_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Young Toys\n",
    "# Ignorant group\n",
    "young_toys_ignorant = brand_perception_by_knowledge[2][0]\n",
    "young_toys_ignorant_average = young_toys_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "young_toys_moderate = brand_perception_by_knowledge[2][1]\n",
    "young_toys_moderate_average = young_toys_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "young_toys_knowledgeable = brand_perception_by_knowledge[2][2]\n",
    "young_toys_knowledgeable_average = young_toys_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Oxford\n",
    "# Ignorant group\n",
    "oxford_ignorant = brand_perception_by_knowledge[3][0]\n",
    "oxford_ignorant_average = oxford_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "oxford_moderate = brand_perception_by_knowledge[3][1]\n",
    "oxford_moderate_average = oxford_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "oxford_knowledgeable = brand_perception_by_knowledge[3][2]\n",
    "oxford_knowledgeable_average = oxford_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Froebel\n",
    "# Ignorant group\n",
    "froebel_ignorant = brand_perception_by_knowledge[4][0]\n",
    "oxford_ignorant_average = oxford_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "froebel_moderate = brand_perception_by_knowledge[4][1]\n",
    "froebel_moderate_average = froebel_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "froebel_knowledgeable = brand_perception_by_knowledge[4][2]\n",
    "froebel_knowledgeable_average = froebel_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Montessori\n",
    "# Ignorant group\n",
    "montessori_ignorant = brand_perception_by_knowledge[5][0]\n",
    "montessori_ignorant_average = montessori_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "montessori_moderate = brand_perception_by_knowledge[5][1]\n",
    "montessori_moderate_average = montessori_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "montessori_knowledgeable = brand_perception_by_knowledge[5][2]\n",
    "montessori_knowledgeable_average = montessori_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Edu Hansol\n",
    "# Ignorant group\n",
    "edu_hansol_ignorant = brand_perception_by_knowledge[6][0]\n",
    "edu_hansol_ignorant_average = edu_hansol_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "edu_hansol_moderate = brand_perception_by_knowledge[6][1]\n",
    "edu_hansol_moderate_average = edu_hansol_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "edu_hansol_knowledgeable = brand_perception_by_knowledge[6][2]\n",
    "edu_hansol_knowledgeable_average = edu_hansol_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Riot Games\n",
    "# Ignorant group\n",
    "riot_games_ignorant = brand_perception_by_knowledge[7][0]\n",
    "riot_games_ignorant_average = riot_games_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "riot_games_moderate = brand_perception_by_knowledge[7][1]\n",
    "riot_games_moderate_average = riot_games_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "riot_games_knowledgeable = brand_perception_by_knowledge[7][2]\n",
    "riot_games_knowledgeable_average = riot_games_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# PUBG\n",
    "# Ignorant group\n",
    "pubg_ignorant = brand_perception_by_knowledge[8][0]\n",
    "pubg_ignorant_average = pubg_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "pubg_moderate = brand_perception_by_knowledge[8][1]\n",
    "pubg_moderate_average = pubg_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "pubg_knowledgeable = brand_perception_by_knowledge[8][2]\n",
    "pubg_knowledgeable_average = pubg_knowledgeable.describe().iloc[1,:3]\n",
    "\n",
    "# Mojang\n",
    "# Ignorant group\n",
    "mojang_ignorant = brand_perception_by_knowledge[9][0]\n",
    "mojang_ignorant_average = mojang_ignorant.describe().iloc[1,:3]\n",
    "\n",
    "# Moderate Group\n",
    "mojang_moderate = brand_perception_by_knowledge[9][1]\n",
    "mojang_moderate_average = mojang_moderate.describe().iloc[1,:3]\n",
    "\n",
    "# Knowledgeable Group\n",
    "mojang_knowledgeable = brand_perception_by_knowledge[9][2]\n",
    "mojang_knowledgeable_average = mojang_knowledgeable.describe().iloc[1,:3]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all the datasets by the level of knowledge.\n",
    "# Set the hyper parameter\n",
    "price_index = [i*3 for i in range(10)]    \n",
    "purpose_index = [i*3+1 for i in range(10)]\n",
    "popularity_index = [i*3+2 for i in range(10)]\n",
    "    \n",
    "# Get the ignorant perceptual data.\n",
    "ignorant_average = [lego_ignorant_average, sonogong_ignorant_average, \n",
    "            young_toys_ignorant_average, oxford_ignorant_average, \\\n",
    "            froebel_knowledgeable_average, montessori_knowledgeable_average, \n",
    "            edu_hansol_ignorant_average, riot_games_ignorant_average,\n",
    "            pubg_ignorant_average, mojang_ignorant_average]\n",
    "\n",
    "ignorant = pd.concat(ignorant_average, axis = 0)\n",
    "ignorant\n",
    "\n",
    "ignorant_price = ignorant[price_index]\n",
    "ignorant_purpose = ignorant[purpose_index]\n",
    "ignorant_popularity = ignorant[popularity_index]\n",
    "\n",
    "# Convert the values into lists\n",
    "ignorant_price = list(ignorant_price)\n",
    "ignorant_purpose = list(ignorant_purpose)\n",
    "ignorant_popularity = list(ignorant_popularity)\n",
    "\n",
    "# The moderate.\n",
    "moderate_average = [lego_moderate_average, sonogong_moderate_average, \n",
    "            young_toys_moderate_average, oxford_moderate_average, \\\n",
    "            froebel_knowledgeable_average, montessori_knowledgeable_average, \n",
    "            edu_hansol_moderate_average, riot_games_moderate_average,\n",
    "            pubg_moderate_average, mojang_moderate_average]\n",
    "\n",
    "moderate = pd.concat(moderate_average, axis = 0)\n",
    "moderate\n",
    "\n",
    "moderate_price = moderate[price_index]\n",
    "moderate_purpose = moderate[purpose_index]\n",
    "moderate_popularity = moderate[popularity_index]\n",
    "\n",
    "# Convert the values into lists\n",
    "moderate_price = list(moderate_price)\n",
    "moderate_purpose = list(moderate_purpose)\n",
    "moderate_popularity = list(moderate_popularity)\n",
    "    \n",
    "# The Knowledgeable.\n",
    "knowledgeable_average = [lego_knowledgeable_average, sonogong_knowledgeable_average, \n",
    "            young_toys_knowledgeable_average, oxford_knowledgeable_average, \n",
    "            froebel_knowledgeable_average, montessori_knowledgeable_average, \n",
    "            edu_hansol_knowledgeable_average, riot_games_knowledgeable_average,\n",
    "            pubg_knowledgeable_average, mojang_knowledgeable_average]\n",
    "\n",
    "knowledgeable = pd.concat(knowledgeable_average, axis = 0)\n",
    "knowledgeable\n",
    "\n",
    "knowledgeable_price = knowledgeable[price_index]\n",
    "knowledgeable_purpose = knowledgeable[purpose_index]\n",
    "knowledgeable_popularity = knowledgeable[popularity_index]\n",
    "\n",
    "# Convert the values into lists\n",
    "knowledgeable_price = list(knowledgeable_price)\n",
    "knowledgeable_purpose = list(knowledgeable_purpose)\n",
    "knowledgeable_popularity = list(knowledgeable_popularity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Encoding the last datset (marketing mix dataset)\n",
    "import NStats as ns\n",
    "\n",
    "# Preprocesing for Regression Analysis.\n",
    "mix\n",
    "mix.describe()\n",
    "\n",
    "mix_product = mix.iloc[:,:4]\n",
    "mix_price = mix.iloc[:,4:8]\n",
    "mix_place = mix.iloc[:,8:12]\n",
    "mix_promotion = mix.iloc[:,12:16]\n",
    "\n",
    "# Reliabiltiy.\n",
    "r = ns.Reliability()\n",
    "r.analyse(mix_product)\n",
    "r.analyse(mix_price)\n",
    "r.analyse(mix_place)\n",
    "r.analyse(mix_promotion)\n",
    "\n",
    "mix_product.corr().iloc[0,:]\n",
    "np.mean(mix_product.corr().iloc[0,:])\n",
    "\n",
    "# Create ID column as the first column.\n",
    "demo[\"id\"] = [i+1 for i in range(demo.shape[0])]\n",
    "demo = demo[[\"id\",'sex', 'region', 'bought', 'my_purpose', 'age', 'income', 'accuracy1',\n",
    "       'accuracy2', 'accuracy3', 'accuracy4', 'accuracy5', 'accuracy6',\n",
    "       'accuracy7', 'accuracy8', 'accuracy9', 'accuracy10']]\n",
    "\n",
    "# Concatenate demographic and marketing mix columns (especially, for the regression analysis)\n",
    "#demo_mix = pd.concat([demo, mix], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Perceptual Map Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define a function that flattens the lists of lists.\n",
    "def flatten(list):\n",
    "    flattened_list = []\n",
    "    for i in range(len(list)):\n",
    "        for j in range(len(list[i])):\n",
    "            flattened_list.append(list[i][j])\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Hyperparameters\n",
    "brand_names =[\"Lego\", \"Sonogong\", \n",
    "              \"Young Toys\", \"Oxford\",\n",
    "              \"Froebel\", \"Montessori\",\n",
    "              \"Edu Hansol\", \"Riot Games\",\n",
    "              \"PUBG\", \"Mojang\"]\n",
    "\n",
    "colors = [\"blue\", \"green\", \"red\"]\n",
    "markers = [\"o\", \"^\", \"x\"]\n",
    "industries = [\"Toys\", \"Education\", \"Games\"]\n",
    "\n",
    "color_range = [[0]] + [[i] * 3 for i in range(3)]\n",
    "color_range_flattened = flatten(color_range)\n",
    "\n",
    "marker_range = [[0]] + [[i, i+1, i+2] * 3 for i in range(1)]\n",
    "marker_range_flattened = flatten(marker_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% The knowledgeable.\n",
    "import pandas as pd\n",
    "\n",
    "# Get the axes.\n",
    "fig3 = plt.figure()\n",
    "ax = fig3.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get the data.\n",
    "X1 = pp.knowledgeable_price\n",
    "Y1 = pp.knowledgeable_purpose\n",
    "Z1 = pp.knowledgeable_popularity\n",
    "\n",
    "# Check the coordinates.\n",
    "#coord = pd.DataFrame(data = {\"price\": X1, \"purpose\": Y1, \"popularity\": Z1})\n",
    "#coord.index = brand_names\n",
    "#coord = coord.round(2)\n",
    "#writer = pd.ExcelWriter('coords.xlsx')\n",
    "#coord.to_excel(writer)\n",
    "#writer.save()\n",
    "\n",
    "# Plot the data\n",
    "for i in range(10): \n",
    "    ax.scatter(X1[i], Y1[i], Z1[i], label = brand_names[i], \\\n",
    "               c = colors[color_range_flattened[i]], marker = markers[marker_range_flattened[i]], \\\n",
    "               s=100)\n",
    "    \n",
    "# Plot the text\n",
    "for i in range(len(brand_names)):\n",
    "    ax.text(X1[i], Y1[i], Z1[i], brand_names[i], fontsize = 12)\n",
    "\n",
    "# Set the axes range\n",
    "ax.set_xlim3d(1, 10)\n",
    "ax.set_ylim3d(1, 10)\n",
    "ax.set_zlim3d(1, 10)\n",
    "\n",
    "# Set the lable\n",
    "ax.set_xlabel(\"Low Price vs. High Price\", fontsize = 12)\n",
    "ax.set_ylabel(\"Education vs. Entertainment\", fontsize = 12)\n",
    "ax.set_zlabel(\"High Popularity vs. Low Popularity\", fontsize = 12)\n",
    "ax.set_title(\"Perceptual Map\", fontsize = 20)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=1, borderaxespad=0.)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Mean Compare\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "\n",
    "# Create a table with mean of each mixes.\n",
    "# Mean\n",
    "mix_overall_mean = np.mean(pp.mix.iloc[:,-1])\n",
    "mix_product_mean_total = np.mean(np.mean(pp.mix_product))\n",
    "mix_price_mean_total = np.mean(np.mean(pp.mix_price))\n",
    "mix_place_mean_total = np.mean(np.mean(pp.mix_place))\n",
    "mix_promotion_mean_total = np.mean(np.mean(pp.mix_promotion))\n",
    "\n",
    "mix_product_mean = pd.DataFrame(np.mean(pp.mix_product)).T\n",
    "mix_product_mean.insert(column = \"product_mean\", value = mix_product_mean_total, loc = 4)\n",
    "\n",
    "mix_price_mean = pd.DataFrame(np.mean(pp.mix_price)).T\n",
    "mix_price_mean.insert(column = \"price_mean\", value = mix_price_mean_total, loc = 4)\n",
    "\n",
    "mix_place_mean = pd.DataFrame(np.mean(pp.mix_place)).T\n",
    "mix_place_mean.insert(column = \"place_mean\", value = mix_place_mean_total, loc = 4)\n",
    "\n",
    "mix_promotion_mean = pd.DataFrame(np.mean(pp.mix_promotion)).T\n",
    "mix_promotion_mean.insert(column = \"promotion_mean\", value = mix_promotion_mean_total, loc = 4)\n",
    "\n",
    "# Intra-comparison\n",
    "# Get mean\n",
    "mix_product_mean\n",
    "mix_price_mean\n",
    "mix_place_mean\n",
    "mix_promotion_mean\n",
    "\n",
    "\n",
    "#mix_product_tscore = st.tscore(mix_product_mean.iloc[0,:4])\n",
    "#mix_price_tscore = st.tscore(mix_price_mean.iloc[0,:4])\n",
    "#mix_place_tscore = st.tscore(mix_place_mean.iloc[0,:4])\n",
    "#mix_promotion_tscore = st.tscore(mix_promotion_mean.iloc[0,:4])\n",
    "\n",
    " \n",
    "#%% Inter-comparison\n",
    "mix_mean_overall_dict = {\n",
    "        \"product\": [mix_product_mean_total],\n",
    "        \"price\": [mix_price_mean_total],\n",
    "        \"place\": [mix_place_mean_total],\n",
    "        \"promotion\": [mix_promotion_mean_total],\n",
    "        \"overall\": [mix_overall_mean],\n",
    "        \"average\": np.mean([mix_product_mean_total, mix_price_mean_total, mix_place_mean_total, mix_promotion_mean_total])        \n",
    "                 }\n",
    "mix_mean_overall = pd.DataFrame(data=mix_mean_overall_dict)\n",
    "mix_mean_overall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
